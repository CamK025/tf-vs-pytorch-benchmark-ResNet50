{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b90048-e486-4fbc-8ca0-6df170ba2e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/10: 100%|██████████| 32/32 [04:07<00:00,  7.74s/it, acc=0.0127, loss=4.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Done - Avg Loss: 149.4919 - Acc: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 32/32 [04:13<00:00,  7.92s/it, acc=0.0275, loss=4.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Done - Avg Loss: 146.2408 - Acc: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 32/32 [04:03<00:00,  7.62s/it, acc=0.0275, loss=4.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Done - Avg Loss: 143.3066 - Acc: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 32/32 [04:12<00:00,  7.88s/it, acc=0.0461, loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Done - Avg Loss: 138.7973 - Acc: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 32/32 [04:11<00:00,  7.86s/it, acc=0.0529, loss=4.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Done - Avg Loss: 136.3688 - Acc: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 32/32 [04:05<00:00,  7.68s/it, acc=0.0725, loss=4.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Done - Avg Loss: 132.0986 - Acc: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 32/32 [04:14<00:00,  7.94s/it, acc=0.0647, loss=4.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Done - Avg Loss: 130.2710 - Acc: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 32/32 [04:05<00:00,  7.67s/it, acc=0.0706, loss=3.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Done - Avg Loss: 128.6890 - Acc: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 32/32 [04:14<00:00,  7.96s/it, acc=0.0706, loss=3.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Done - Avg Loss: 125.7033 - Acc: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 32/32 [04:12<00:00,  7.89s/it, acc=0.0892, loss=3.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Done - Avg Loss: 123.6617 - Acc: 0.0892\n",
      "Done. Model and metrics saved in: experiments/PyTorch_resnet50_bs32_lr0.001_e10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import json\n",
    "\n",
    "# ==== 参数 ====\n",
    "with open(\"config/exp1_resnet50_bs32_lr1e-3.json\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BATCH_SIZE = cfg[\"batch_size\"]\n",
    "LR = cfg[\"learning_rate\"]\n",
    "EPOCHS = cfg[\"epochs\"]\n",
    "IMG_SIZE = cfg[\"img_size\"]\n",
    "NUM_CLASSES = cfg[\"num_classes\"]\n",
    "EXPERIMENT_NAME = f\"PyTorch_{cfg['model_name']}_bs{BATCH_SIZE}_lr{LR}_e{EPOCHS}\"\n",
    "MODEL_DIR = os.path.join(\"experiments\", EXPERIMENT_NAME)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== 记录资源 ====\n",
    "process = psutil.Process()\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "start_time = time.time()\n",
    "\n",
    "# ==== 数据加载（Flowers102）====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\", split=\"train\", download=True, transform=transform)\n",
    "val_dataset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\", split=\"val\", download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# ==== 构建模型（冻结 base）====\n",
    "base_model = models.resnet50(pretrained=True)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "# 替换分类头（102类）\n",
    "base_model.fc = nn.Sequential(\n",
    "    nn.Linear(base_model.fc.in_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 102)\n",
    ")\n",
    "base_model = base_model.to(DEVICE)\n",
    "\n",
    "# ==== 损失函数与优化器 ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.fc.parameters(), lr=LR)\n",
    "\n",
    "# ==== 模型训练 ====\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    base_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = base_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "\n",
    "        acc = total_correct / len(train_dataset)\n",
    "        loop.set_postfix(loss=loss.item(), acc=acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Done - Avg Loss: {total_loss:.4f} - Acc: {acc:.4f}\")\n",
    "\n",
    "\n",
    "training_duration = time.time() - start_time\n",
    "if DEVICE.type == \"cuda\":\n",
    "    memory_usage_mb = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "else:\n",
    "    memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "    memory_usage_mb = memory_after - memory_before\n",
    "\n",
    "# ==== 保存模型 ====\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "torch.save(base_model.state_dict(), os.path.join(MODEL_DIR, \"resnet50_flower.pt\"))\n",
    "\n",
    "# ==== 模型评估 ====\n",
    "base_model.eval()\n",
    "correct = 0\n",
    "total_loss = 0.0\n",
    "inference_start = time.time()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = base_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item() * images.size(0)  \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "inference_end = time.time()\n",
    "\n",
    "val_loss = total_loss / len(val_dataset)\n",
    "val_acc = correct / len(val_dataset)\n",
    "\n",
    "\n",
    "# ==== 记录性能指标 ====\n",
    "metrics = {\n",
    "    \"training_time_seconds\": training_duration,\n",
    "    \"memory_usage_mb\": memory_after - memory_before,\n",
    "    \"inference_latency_seconds\": inference_end - inference_start,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_accuracy\": val_acc,\n",
    "}\n",
    "with open(os.path.join(MODEL_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "with open(os.path.join(MODEL_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Done. Model and metrics saved in:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c1d0f1-a526-4481-8831-b494611d42dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/envs/pytorch/lib/python3.10/site-packages/~umpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cb3135-39ca-402a-b419-a132969fcb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd1331-f9ad-42da-abb7-bbcfc2156fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
