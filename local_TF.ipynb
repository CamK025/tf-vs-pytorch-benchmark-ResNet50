{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd054a1-2194-4396-a0cd-624010c0ee90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 05:09:17.316119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-05-27 05:09:17.318119: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-05-27 05:09:17.318285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (google-summer-01): /proc/driver/nvidia/version does not exist\n",
      "2025-05-27 05:09:17.334871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 328.90 MiB (download: 328.90 MiB, generated: 331.34 MiB, total: 660.25 MiB) to /home/jupyter/tensorflow_datasets/oxford_flowers102/2.1.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176b7327d9c842a4bea411955e6602e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a6663c679441d9ac72f84855151e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a909efda7514758a5d13d69f4f1325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1020 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jupyter/tensorflow_datasets/oxford_flowers102/2.1.1.incomplete5JFH4K/oxford_flowers102-train.t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/6149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jupyter/tensorflow_datasets/oxford_flowers102/2.1.1.incomplete5JFH4K/oxford_flowers102-test.tf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/1020 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jupyter/tensorflow_datasets/oxford_flowers102/2.1.1.incomplete5JFH4K/oxford_flowers102-validat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset oxford_flowers102 downloaded and prepared to /home/jupyter/tensorflow_datasets/oxford_flowers102/2.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 05:10:23.933920: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:549] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 05:10:24.194995: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 146s 5s/step - loss: 4.7113 - accuracy: 0.0350\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 134s 5s/step - loss: 4.1998 - accuracy: 0.0862\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 135s 5s/step - loss: 3.6258 - accuracy: 0.1937\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 142s 6s/step - loss: 3.0143 - accuracy: 0.3013\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 143s 6s/step - loss: 2.5313 - accuracy: 0.3963\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 133s 5s/step - loss: 2.1104 - accuracy: 0.4625\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 132s 5s/step - loss: 1.7470 - accuracy: 0.5562\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 138s 6s/step - loss: 1.5122 - accuracy: 0.6100\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 134s 5s/step - loss: 1.2376 - accuracy: 0.6925\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 135s 5s/step - loss: 1.1482 - accuracy: 0.7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments/TF_resnet50_bs32_lr0.001_e10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments/TF_resnet50_bs32_lr0.001_e10/assets\n",
      "2025-05-27 05:34:21.230939: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:549] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
      "2025-05-27 05:34:21.464950: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 35s 5s/step - loss: 1.5743 - accuracy: 0.6373\n",
      "Done. Model and metrics saved in: experiments/TF_resnet50_bs32_lr0.001_e10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "import psutil\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ==== 配置参数 ====\n",
    "with open(\"config/exp1_resnet50_bs32_lr1e-3.json\") as f:\n",
    "    cfg = json.load(f)\n",
    "    \n",
    "BATCH_SIZE = cfg[\"batch_size\"]\n",
    "LR = cfg[\"learning_rate\"]\n",
    "EPOCHS = cfg[\"epochs\"]\n",
    "IMG_SIZE = cfg[\"img_size\"]\n",
    "NUM_CLASSES = cfg[\"num_classes\"]\n",
    "\n",
    "EXPERIMENT_NAME = f\"TF_{cfg['model_name']}_bs{BATCH_SIZE}_lr{LR}_e{EPOCHS}\"\n",
    "MODEL_DIR = os.path.join(\"experiments\", EXPERIMENT_NAME)\n",
    "\n",
    "DISTRIBUTE = \"single\"\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "\n",
    "# ==== 设置分布式策略 ====\n",
    "if DISTRIBUTE == \"single\":\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\" if tf.config.list_physical_devices('GPU') else \"/cpu:0\")\n",
    "elif DISTRIBUTE == \"mirror\":\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "elif DISTRIBUTE == \"multi\":\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "dataset_info = tfds.builder(\"oxford_flowers102\").info\n",
    "TRAIN_EXAMPLES = int(dataset_info.splits[\"train\"].num_examples * 0.8)\n",
    "STEPS = TRAIN_EXAMPLES // (BATCH_SIZE * strategy.num_replicas_in_sync)\n",
    "\n",
    "# ==== 记录训练前内存 ====\n",
    "process = psutil.Process()\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "start_time = time.time()\n",
    "\n",
    "# ==== 数据预处理函数 ====\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    return image, label\n",
    "\n",
    "# ==== 加载 Flowers102 数据 ====\n",
    "ds_train = tfds.load(\"oxford_flowers102\", split=\"train[:80%]\", as_supervised=True)\n",
    "ds_val = tfds.load(\"oxford_flowers102\", split=\"train[80%:]\", as_supervised=True)\n",
    "\n",
    "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE * strategy.num_replicas_in_sync).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ==== 构建模型 ====\n",
    "with strategy.scope():\n",
    "    base_model = keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(NUM_CLASSES, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# ==== 模型训练 ====\n",
    "model.fit(ds_train, epochs=EPOCHS, steps_per_epoch=STEPS)\n",
    "\n",
    "training_duration = time.time() - start_time\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "\n",
    "# ==== 保存模型 ====\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "tf.saved_model.save(model, MODEL_DIR)\n",
    "\n",
    "# ==== 模型评估 ====\n",
    "eval_start = time.time()\n",
    "val_loss, val_acc = model.evaluate(ds_val)\n",
    "eval_end = time.time()\n",
    "inference_latency = eval_end - eval_start\n",
    "\n",
    "# ==== 记录指标 ====\n",
    "metrics = {\n",
    "    \"training_time_seconds\": training_duration,\n",
    "    \"memory_usage_mb\": memory_after - memory_before,\n",
    "    \"inference_latency_seconds\": inference_latency,\n",
    "    \"test_loss\": val_loss,\n",
    "    \"test_accuracy\": val_acc\n",
    "}\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "with open(os.path.join(MODEL_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Done. Model and metrics saved in:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb769d7-fff3-46b3-bf76-86fffae1c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49d1ed8-cac2-4980-b293-3c69761568df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
